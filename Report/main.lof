\contentsline {figure}{\numberline {1}{\ignorespaces The framework of \texttt {EasyJailbreak}, which includes three stages: the preparation stage, attack stage, and output stage (from left to right). In the preparation stage, users need to configure the jailbreak settings, e.g., jailbreak instructions (queries), initial prompt template (seeds). In the attack stage, \texttt {Easyjailbreak} iteratively updates the attack input (upper dashed box), attacks the target model, and evaluates the result (lower dashed box) based on the configuration. Finally, users receive a report containing essential information, such as the Attack Success Rate.}}{6}{figure.caption.6}%
\contentsline {figure}{\numberline {2}{\ignorespaces An example response generated by GPT under a jailbreak attack using the PAIR method \blx@tocontentsinit {0}\cite {pair}.}}{10}{figure.caption.8}%
\contentsline {figure}{\numberline {3}{\ignorespaces Attack Success Rate (ASR) comparison for GPT and LLaMA2 models.}}{11}{figure.caption.9}%
\contentsline {figure}{\numberline {4}{\ignorespaces Attack Success Rate and Efficiency comparison for LLaMA2-7B and Llama2-13B models.}}{12}{figure.caption.10}%
\contentsline {figure}{\numberline {5}{\ignorespaces Time-resource trade-offs for various attack methods.}}{13}{figure.caption.11}%
\contentsline {figure}{\numberline {6}{\ignorespaces A visual representation of key challenges and solutions in LLM security evaluation.}}{13}{figure.caption.13}%
